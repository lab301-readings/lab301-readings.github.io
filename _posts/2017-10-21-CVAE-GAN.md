---
layout:     post
title:      CVAE-GAN
subtitle:   Generative model
date:       2017-10-21
author:     Daxin
header-img: img/post-bg-hacker.jpg
catalog: true
tags:
    - deep learning
    - GAN
    - VAE

---

# Introduction
- Present a general learning framework that combines **a variational auto-encoder(VAE)** with a **generative adversarial network(GAN)**.
- Propose a new **objective** for the generator. Instead of using the same cross entropy loss as the discriminator network, the new objective requires the generator to generate data that minimize the `l2` distance of average feature to the real data.  

The result of this work is as follows. 

![](https://ws1.sinaimg.cn/large/006tKfTcgy1fkpwqb5f4nj30fs0b6di9.jpg)

---
# Related Work
## Variational Auto-encoder (VAE) 
![](https://ws4.sinaimg.cn/large/006tKfTcgy1fkpwvh31jxj307a01eglf.jpg)  

Here E represents `Encoder` and G represents `Generator`. `z` is a latent verctor from input `x`. `x'` is generated from `z`.

## Generative Adversarial Network (GAN) 
![](https://ws2.sinaimg.cn/large/006tKfTcgy1fkpwygjwmrj306i016a9v.jpg)  

GAN has a `Discriminative` network represented by `D`. The discriminator `D` tries to distinguish real training data from synthesized data; and the generator `G` tries to fool the discriminator.

## CVAE && CGAN
![](https://ws4.sinaimg.cn/large/006tKfTcgy1fkpxb7cg6bj309g045glm.jpg)  
VAEs and GANs can also be trained to conduct conditional generation, e.g., *CVAE* and *CGAN*. By introducing additional conditionality, they can handle probabilistic one-to-many mapping problems.
## Performance
![](https://ws2.sinaimg.cn/large/006tKfTcgy1fkpx6xrakyj30jy07i3zx.jpg) 

In the experiment for contrast, the results generated by CVAE are relatively blurry, but the whole structure is maintained, while results generated by CGAN miss the structure of faces.   

How to improve these two models to generate better images? One idea is whether can we combine them to learn from the other's strong points to offset one's weakness.

---
# CVAE-GAN

## The formulation of CVAE-GAN
![](https://ws1.sinaimg.cn/large/006tKfTcgy1fkpxwwrt5gj30ct06jdgj.jpg)  

Where `x` and `x′` are input and generated image. `E`, `G`, `C`, `D` are encoder, generative, classification, and discriminative network, respectively. `z` is the latent vector. `y` is a binary output which represents real/synthesized image. `c` is the condition, such as attribute or class label.

The naive combination of VAE and GAN is insufficient. Recent work shows that if the original `KL` Divergence loss is adopted, training of `GAN`will suffer from a gradient vanishing problem of the network `G`. 

So this work keep the training process of network `E`, `D`, and `C` as the same as the original `VAE` and `GAN`, and propose a new **mean feature matching objective** for the generative network `G` to improve the stability of the original `GAN`. 
## Loss function
`E`, `D`, and `C` are as the same as the original `VAE` and `GAN`. Therefore their loss function is as follows: 
![](https://ws1.sinaimg.cn/large/006tKfTcgy1fkpy5dri4xj30cb021747.jpg)
![](https://ws1.sinaimg.cn/large/006tKfTcgy1fkpy572fezj30e7013748.jpg)
![](https://ws1.sinaimg.cn/large/006tKfTcgy1fkpy5par53j308901f0sl.jpg)  

### Mean feature matching based GAN
To improve the stability of the original `GAN`, this work propose a new **mean feature matching objective** for the generative network `G` which is represented 

![](https://ws3.sinaimg.cn/large/006tKfTcgy1fkpyaggqi4j30tg06i758.jpg)

The objective requires the center of the features of the synthesized samples to match the center of the feature of the real samples. 

### Mean Feature Matching for Conditional Image Generation
For the conditional image generation, this work propose using the mean feature matching objective for generative network G.
![](https://ws2.sinaimg.cn/large/006tKfTcgy1fkpye5ij9fj30cm01ujrc.jpg)  


### Pairwise Feature Matching  
The VAE model in this work can enforce the GAN to generate diverse samples since the encoder network `E` can obtain a mapping from the real image `x` to the latent space `z`. Therefore, the model explicitly sets up the relationship between the latent space and real image space. 

The loss of `G` in this part is 
![](https://ws1.sinaimg.cn/large/006tKfTcgy1fkpyjt4mgvj30ci02s3yk.jpg)

### Objective of CVAE-GAN
The goal of this approach is to minimize the following loss function:
![](https://ws4.sinaimg.cn/large/006tKfTcgy1fkpyku3o6fj30x002c3yu.jpg)

In the experiments, λ1 = 3, λ2 = 1, λ3 = 1e10−3 and λ4 = 1e10−3.

---
## Algorithm
The whole training procedure is clear and easy to understand.
![](https://ws4.sinaimg.cn/large/006tKfTcgy1fkpyox899kj309y0f0q4v.jpg)

![](https://ws2.sinaimg.cn/large/006tKfTcgy1fkpypo8ea3j309p08idgd.jpg)

---
# Experiment

## Visualization comparison with other models 
![](https://ws2.sinaimg.cn/large/006tKfTcgy1fkpyrk2envj30k00cjtcd.jpg)
The results generated by CVAE-GAN are difficult to distinguish from the real samples.

## Quantitative comparison 
![](https://ws4.sinaimg.cn/large/006tKfTcgy1fkpyuopa2wj30dr031jrq.jpg)

The higher the score of *Realisticity*, the better.

## Attributes morphing 

Given two latent vectors, `z1` and `z2`, the generated images can change attribute when use the new `z`. 
![](https://ws4.sinaimg.cn/large/006tKfTcgy1fkpyxeadh2j30k009vjtb.jpg)

## Image inpainting 
![](https://ws2.sinaimg.cn/large/006tKfTcgy1fkpz278ky9j30cd099q4c.jpg)

## CVAE-GAN for data augmentation 
![](https://ws3.sinaimg.cn/large/006tKfTcgy1fkpz2klsiij30fu041t9f.jpg)
Two data augmentation strategies: 
generate more images for existing identities in the training datasets; 
generating new identities by mixing of different identities. 

# Conclusion and Discussion

- Present a general learning framework that combines a variational auto-encoder with a generative adversarial network.

- Propose a mean discrepancy objective for the generative network to make the training of the `GAN` more stable.

- Now the model can just generate images from an known category.

# Reference
1. [Bao J, Chen D, Wen F, et al. CVAE-GAN: Fine-Grained Image Generation through Asymmetric Training[J]. 2017.](https://arxiv.org/abs/1703.10155)

